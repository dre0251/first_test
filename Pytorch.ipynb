{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-06T15:48:47.850815Z",
     "start_time": "2025-03-06T15:48:46.428561Z"
    }
   },
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T15:48:47.882257Z",
     "start_time": "2025-03-06T15:48:47.850815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#数据预处理\n",
    "LEARNING_RATE = 0.1\n",
    "n_epochs = 100\n",
    "n_points = 10\n",
    "data = torch.rand(n_points, 2) * 2 - 1 \n",
    "labels = (data.norm(dim = 1) > 0.7).float().unsqueeze(1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data.to(device)\n",
    "labels.to(device)\n",
    "\n",
    "#创建模型类\n",
    "class CircleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(2,20)\n",
    "        self.layer2 = nn.Linear(20,1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.sigmoid(self.layer2(x))\n",
    "        return x\n",
    "        \n",
    "#实例化\n",
    "model = CircleClassifier()\n",
    "model = model.to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad() #梯度归零\n",
    "    predictions = model(data)\n",
    "    loss = loss_fn(predictions, labels)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item(): .4f}\")\n"
   ],
   "id": "197e1f0e10941a64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss:  0.6579\n",
      "Epoch 20, Loss:  0.6579\n",
      "Epoch 40, Loss:  0.6579\n",
      "Epoch 60, Loss:  0.6579\n",
      "Epoch 80, Loss:  0.6579\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:29:45.263075Z",
     "start_time": "2025-03-06T16:29:45.253153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#超参数\n",
    "torch.manual_seed(42)\n",
    "batch_size = 8\n",
    "block_size = 32\n",
    "learning_rate = 0.0003\n",
    "max_iters = 100\n",
    "n_embd = 16\n",
    "wrap_width = 50"
   ],
   "id": "10e0c279e7f95895",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:29:46.882726Z",
     "start_time": "2025-03-06T16:29:46.829329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "file_name = \"hongloumeng.txt\"\n",
    "\n",
    "with open(file_name, \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text)"
   ],
   "id": "e1a73f4ad04ec34b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T15:48:48.168525Z",
     "start_time": "2025-03-06T15:48:47.947937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#有序、不重复的列表\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "#字符和整数之间的投影\n",
    "stoi = {ch : i for i,ch in enumerate(chars)}#符号到整数\n",
    "itos = {i : ch for i,ch in enumerate(chars)}#整数到符号\n",
    "encode = lambda str1:[stoi[c] for c in str1]#编码，把字符串转化为数字串（列表）\n",
    "decode = lambda list1:\"\".join([itos[i] for i in list1])#解码，把数字转换为字符串\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n"
   ],
   "id": "803be5b498cfaa3a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T15:48:48.184627Z",
     "start_time": "2025-03-06T15:48:48.168525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    # token_list = x.tolist()\n",
    "    # for str_list in token_list:\n",
    "    #   print(decode(str_list))\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x,y\n",
    "get_batch(\"train\")"
   ],
   "id": "7a8033f38cc13737",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 688, 2687, 2687, 2687, 2687, 2687,  497, 2687, 2687,  579, 2687, 2687,\n",
       "          2687,  359, 2687, 2687],\n",
       "         [ 161, 2687, 2687, 2687, 2687, 2687,  517, 2687, 2687, 2687, 2687, 2687,\n",
       "           333, 2687, 2687, 2687],\n",
       "         [2687, 2687,  365, 2687,  364, 2687, 2687, 2687, 2687, 2687, 2687,  586,\n",
       "          2687, 2687, 2687, 2687]]),\n",
       " tensor([[2687, 2687, 2687, 2687, 2687,  497, 2687, 2687,  579, 2687, 2687, 2687,\n",
       "           359, 2687, 2687, 2258],\n",
       "         [2687, 2687, 2687, 2687, 2687,  517, 2687, 2687, 2687, 2687, 2687,  333,\n",
       "          2687, 2687, 2687, 2687],\n",
       "         [2687,  365, 2687,  364, 2687, 2687, 2687, 2687, 2687, 2687,  586, 2687,\n",
       "          2687, 2687, 2687, 2687]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T15:48:48.200442Z",
     "start_time": "2025-03-06T15:48:48.184627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "size = 3  #几个值需要做嵌入\n",
    "n_embedding = 4  #嵌入后的维度\n",
    "\n",
    "embedding_table = nn.Embedding(size, n_embedding)\n",
    "# idx = torch.tensor([0,1,2,3,4,5,6,7,8,9])\n",
    "idx = torch.arange(3)\n",
    "print(embedding_table(idx))"
   ],
   "id": "829731444b0c85f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303],\n",
      "        [-1.1229, -0.1863,  2.2082, -0.6380],\n",
      "        [ 0.4617,  0.2674,  0.5349,  0.8094]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T15:48:48.216400Z",
     "start_time": "2025-03-06T15:48:48.200442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x,y = get_batch(\"train\")\n",
    "print(x)\n"
   ],
   "id": "fac939f5da2f2451",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2687, 2687, 2687, 2687, 2687,  174, 2687, 2687, 2687, 2687,  362,  646,\n",
      "         2687, 2687, 2687, 2687],\n",
      "        [ 286,  255, 2687,  344, 2687, 2687, 2687,  403, 2687, 2687, 2687, 2687,\n",
      "         2687, 2687, 2687, 2687],\n",
      "        [2687, 2687, 2687, 2687, 2687, 2687, 2687, 2687, 2687, 2687, 2687, 2687,\n",
      "         2687, 2687, 2687, 2687]])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T15:48:48.232141Z",
     "start_time": "2025-03-06T15:48:48.216400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "token_embd = token_embedding_table(x)\n",
    "position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "position_idx = torch.arange(block_size)\n",
    "position_emb = position_embedding_table(position_idx)\n",
    "\n",
    "print(\"token_embd\",token_embd)\n",
    "x_list = x.tolist()\n",
    "for str_list in x_list:\n",
    "    decoded_str = decode(str_list)\n",
    "    print(decoded_str)\n",
    "\n",
    "print(\"token_embd\",token_embd)\n",
    "print(\"position_emb\",position_emb)"
   ],
   "id": "f77480a0f59ef76e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embd tensor([[[ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 0.9874,  0.6415, -1.3313],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [-1.1304,  0.9965,  0.3934],\n",
      "         [ 0.3149, -0.2943, -1.3962],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749]],\n",
      "\n",
      "        [[-0.2800, -1.2407,  0.7410],\n",
      "         [-0.7347,  0.0447, -1.5211],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 0.5015,  0.3946, -0.7586],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 0.9233, -0.4852, -0.5536],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749]],\n",
      "\n",
      "        [[ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749]]], grad_fn=<EmbeddingBackward0>)\n",
      "�����Ŷ����˳Է����\n",
      "ɥȥ�ˡ���̽��������\n",
      "����������������\n",
      "token_embd tensor([[[ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 0.9874,  0.6415, -1.3313],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [-1.1304,  0.9965,  0.3934],\n",
      "         [ 0.3149, -0.2943, -1.3962],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749]],\n",
      "\n",
      "        [[-0.2800, -1.2407,  0.7410],\n",
      "         [-0.7347,  0.0447, -1.5211],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 0.5015,  0.3946, -0.7586],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 0.9233, -0.4852, -0.5536],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749]],\n",
      "\n",
      "        [[ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749],\n",
      "         [ 1.5932,  0.8239,  0.1749]]], grad_fn=<EmbeddingBackward0>)\n",
      "position_emb tensor([[-7.7242e-01,  4.6676e-02,  5.8791e-01],\n",
      "        [-1.3847e+00,  2.9872e-01,  1.1335e+00],\n",
      "        [ 3.8159e-01,  8.0929e-01, -8.3080e-02],\n",
      "        [-1.9507e+00, -3.7444e-01,  5.7943e-01],\n",
      "        [ 2.8811e-01,  1.5037e+00, -1.3726e+00],\n",
      "        [ 1.7528e+00, -1.7533e-01, -3.3886e-02],\n",
      "        [ 6.8622e-01,  1.0350e+00, -2.7934e-01],\n",
      "        [-4.3165e-01,  2.7717e+00,  9.6106e-01],\n",
      "        [ 3.1297e-01, -3.9791e-01,  4.2677e-01],\n",
      "        [ 8.5171e-01, -1.3466e-01, -6.6219e-01],\n",
      "        [ 1.2675e-01, -3.8538e-01, -8.4775e-01],\n",
      "        [ 4.5959e-01,  2.6709e-03,  1.2469e+00],\n",
      "        [-1.2222e+00,  2.3332e-01,  4.3095e-02],\n",
      "        [-9.8913e-01, -9.9427e-02, -1.2274e+00],\n",
      "        [-1.9667e+00,  8.9250e-01, -7.9763e-01],\n",
      "        [ 1.8752e-01,  2.5750e-01, -1.1567e+00]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:31:57.829499Z",
     "start_time": "2025-03-06T16:31:57.805459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#傻瓜模型\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.network1 = nn.Linear(n_embd, 100)\n",
    "        self.network2 = nn.Linear(100, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets = None):\n",
    "        B,T = idx.shape  #B=batch_size  T=block_size\n",
    "        token_embd = self.token_embedding_table(idx)\n",
    "        position_idx = torch.arange(T)\n",
    "        position_emb = self.position_embedding_table(position_idx)\n",
    "        x = token_embd + position_emb #(B, T, n_embed)\n",
    "        logits = torch.relu(self.network1(x)) #(B, T, vocab_size)\n",
    "        logits = self.network2(logits) #(B, T, vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits,loss\n",
    "    def generate(self, token_sequ, max_new_tokens): #token_sequ已知的上文，max_new_tokens是续写的长度\n",
    "        for _ in range(max_new_tokens):\n",
    "            token_input = token_sequ[:, -block_size: ]\n",
    "            logits, loss = self.forward(token_input)\n",
    "            logits = logits[:, -1 ,:] #logits(B, T, vocab_size) 取最后一个\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            token_next = torch.multinomial(probs, num_samples=1)#把概率分布向量 --> one hot --> token\n",
    "            token_sequ = torch.cat((token_sequ, token_next) , dim = 1)\n",
    "        new_tokens = token_sequ[:, -max_new_tokens :]\n",
    "        return new_tokens\n",
    "            \n",
    "model = LanguageModel()\n",
    "model = model.to(device)\n",
    "out, loss = model(x)\n",
    "print(out.shape)"
   ],
   "id": "92630c87c363b6a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 3508])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:32:03.904301Z",
     "start_time": "2025-03-06T16:32:02.152887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    print(f\"训练内容:{file_name}\")\n",
    "    model = LanguageModel()\n",
    "    model = model.to(device)\n",
    "    print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters') #打印有多少参数\n",
    "    # 设定一个优化器\n",
    "    optimzer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    #循环次数\n",
    "    for i in range(max_iters):\n",
    "        xb, yb = get_batch(\"train\")\n",
    "        logits, loss = model(xb, yb) #前馈运算\n",
    "        optimizer.zero_grad(set_to_none=True) #旧梯队归零\n",
    "        loss.backward() #反向传播，计算新的梯度\n",
    "        optimizer.step() #做一步优化计算\n",
    "    \n",
    "    print(\"训练结束\")\n",
    "    max_new_tokens = 500\n",
    "    start_idx = random.randint(0, len(val_data) - block_size - max_new_tokens)\n",
    "\n",
    "#上文\n",
    "    context = torch.zeros((1, block_size), dtype=torch.long, device=device) #(B, T) B = 1, T = block_size\n",
    "    context[0, :] = val_data[start_idx : start_idx + block_size]\n",
    "    context_str = decode(context[0].tolist())\n",
    "    wrapped_context_str = textwrap.fill(context_str, width = wrap_width)\n",
    "\n",
    "#真实下文\n",
    "    real_next_tokens = torch.zeros((1, max_new_tokens), dtype=torch.long, device=device)\n",
    "    real_next_tokens[0, :] = val_data[start_idx + block_size : start_idx + block_size + max_new_tokens]\n",
    "    real_next_tokens_str = decode(real_next_tokens[0].tolist())\n",
    "    wrapped_real_next_tokens_str = textwrap.fill(real_next_tokens_str, width = wrap_width)\n",
    "\n",
    "#生成下文\n",
    "    generated_tokens = model.generate(context, max_new_tokens)\n",
    "    generated_tokens_str = decode(generated_tokens[0].tolist())\n",
    "    wrapped_generated_tokens_str = textwrap.fill(generated_tokens_str, width = wrap_width)\n",
    "\n",
    "    print(\"上文\")\n",
    "    print(wrapped_context_str)\n",
    "    print(\"真实下文\")\n",
    "    print(wrapped_real_next_tokens_str)\n",
    "    print(\"预测\")\n",
    "    print(wrapped_generated_tokens_str)\n",
    "    \n",
    "main()"
   ],
   "id": "2406be8169e3eb9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练内容:hongloumeng.txt\n",
      "0.412648 M parameters\n",
      "训练结束\n",
      "上文\n",
      "�����Щ���͹�ȥ�ˡ��������˵������Ҵ��\n",
      "真实下文\n",
      "���Ҫ��������Ҳ���ˡ�Ϊʲô���������������ǣ������ǿ޿޺����\n",
      "���ʲô�������ε�������ô˵�أ�����ʹ�á�Ҫ����������������\n",
      "Ǻ�����Щ�Ź֣��Ȼ�һ�����������ֵ��ҿڲ��������ǲ�������ô��\n",
      "������Ǯ�أ��Ͱ��ҵ�ͷ���۱��ˣ�Ҳ�������ء������������ˣ���\n",
      "����Ҳ���ˣ��Ҿ���ô��ա�������Ҳ���ش�ֻ���������������ڱ�\n",
      "��������������˵��������Ҳ���ó�ȥ���Һ�̫̫����Ǯ�����ˡ��\n",
      "�����������񲻻���Ҳʹ�ã�ֻ���һ��õ������һ���źá���Ϯ�˵��Բ�\n",
      "�Ϸ��֣����ױ���������˵���������֣�����ȥ�����ˡ���Ϯ��ֻ�\n",
      "÷��֡�����Ц������������Щ��ԭ�����������ģ����Ǽȷ����ң�\n",
      "�ұ���������ˣ������Ǿ������ǿ�����ô������Ϯ���������ż�\n",
      "预测\n",
      "򡣲ྴ뷡ɽϱ䶼㸣梿η輴Ϫ俿걭賡Ȭ󿪣򵹻Ŵʹ䯵񷴵Ќǰ񮴯Ւ򹷶𣿸𲻳Ṱ忡񻻳䴺󡣵󾹻桮潭񲻰󴣺鸸Ώ󡣴ضǿ俿𣿽󣬳ܹ콫\n",
      "ʨ㸡ⶥ㰲󻹲Ƭ޴ο귽籧絹󻶣򽫶񰲶󰡣籧Ƽַǹ󵽼緹粨篡ﴲ𣡸뱣ﴩ򣬾㰸δ󴬣񣬶޿ಢⰸ𶥽򹩵廨ѿ붯㲢СͰǬꣻ巳⳼׻尰\n",
      "򣬡㵽¢񣬲Я鱬񶼣󸻣澿˥忴ם¶ⷣ񶼴Ȣ⻭򣬷𸮵㻷跽ﴥﴧ𻨣￵硶巳پ򣬡𣿾衱񵹻𣡽ӹ軻𰲣볤Ҽ귵񷹺ƥ㳪亮ɥ﾿뻧⻯﹦ڡ衱\n",
      "ﵯӓȴ쵹ð常򽫶빲I꼮洲㷽롮ը廰ұཱུ緸H򣬲崮ѧ԰ﾣ硰򹩵в瓊㵽ʸ񳯴Ǵࡢľ꾻׷ơ𲡡쵹ӧİ縵ⶪ๸ٯ𶯴ҭ룺\n",
      "൤㽲񴲣뵱ⲻꡰ󲢼ྴ඼ⶥ浱⺣ưڽڮ𣡵񻭶Ⱒ𡣻񱦶𳡣鳪׾ÿʀճ߭鿸𻳣ʪܾ嶯㴷꽫񣬽Ы㱻Ѭ𡮰캷Ű캹ﶬ㴭ﱡᶪ\n",
      "жͬ빫屦ʯį¦칱񳤰񼴱𵤶㼦𿪣ܲݿര뻧쳩𻨣缫꺣š񣬲찲⡣๵⺮Ϸ̲󡣽بﵱƤ仰ﻤ꣡𽱣ꣻ豭仨봦?篣󡰻򡣺¥辡\n",
      "򻯣򽲾绣濾䲻溿󻹲⵹Ľ尲¹塡⽵곪䲢徹淼㷵ѭ涪ٵ𻨾㳢󾹻︽㾳󲻽󷽡󳩣湦β侱񰲶洺巢豭೪󽵸꺵񻻳⼱꼱֪񶼽Ե󽫣鼮﷭ﻣ\n",
      "鿱ⲥ춹󡣿񸴲ӓʲ㼴򲻵ȫ￾䲻񲣬ܾ٧󵨵롯侱ꣿ򶯣챦ﵲ㻰޲缫󵨣鶣󹾹Ӫڷǳ򶯣ձ𹥻㳣Ͱ䰴䵴ɷ볯鶨︧֭뱾輡񣬱貹뷣𱰣\n",
      "󸣽Ƽࡱμ󡣿qڸ񶼣󷽵ǅʪ⸻Էᡢݰ񰮡̨߂ᰮ󤻤̫粢ȏ«軣š峿㼰峤󣬾󲡣޼梷䣺ﻣ򸣽𿪲ܿ󰴷󱾶淯Ϧշ𸻹ﴲ춹輱(籧\n",
      "⺢๸㷣ְhب߹󣬲񡣶鸴ȣῪＰ壻滻췣Yȴްʯ걨˱黳㻺󶼒糤򷴵湷񡢼䵱帯Ѧȏ񣬻游ڣƴ󼪡鲧ӵﹼ澣㼫˹෹걻￸뱯Ң\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T15:48:48.515311Z",
     "start_time": "2025-03-06T15:48:48.499532Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "baf0ec055bc6ebb1",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
