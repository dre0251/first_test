{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-02T07:45:25.467162Z",
     "start_time": "2025-03-02T07:45:25.451251Z"
    }
   },
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:38:19.611365Z",
     "start_time": "2025-03-02T08:38:19.595511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "                                       \n",
    "d_model = 512\n",
    "vocab = 1000\n",
    "\n",
    "x = Variable(torch.LongTensor([[100,2,421,455], [452,334,2,11]]))\n",
    "print(\"x\" , x.shape)\n",
    "emb = Embedding(d_model, vocab)\n",
    "embr = emb(x)\n",
    "print(\"embr\" , embr)\n",
    "print(\"embr\" , embr.shape)\n",
    "\n"
   ],
   "id": "dd99ea143fa2c91b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([2, 4])\n",
      "embr tensor([[[  2.7861,  -5.1170,   7.3297,  ...,   8.7727,  19.0942,  20.0988],\n",
      "         [-33.2384,  10.0533, -14.4355,  ...,  -0.7453,  16.3175,   3.3592],\n",
      "         [-25.0414, -48.5396, -19.7695,  ...,  -9.7313,  26.3012, -12.9687],\n",
      "         [-15.6585,  -0.8350,   1.5748,  ...,  37.0881,  -3.9556,   4.2145]],\n",
      "\n",
      "        [[-42.2173,   8.2238,  23.8643,  ...,  -1.8616,  12.3401, -33.0340],\n",
      "         [-32.5913,  30.7748,   0.3495,  ...,  -8.6518,  29.2767, -32.4875],\n",
      "         [-33.2384,  10.0533, -14.4355,  ...,  -0.7453,  16.3175,   3.3592],\n",
      "         [-23.8018,  30.5947,  -7.3784,  ..., -13.5331,  41.4704,  -5.1295]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "embr torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:38:38.086090Z",
     "start_time": "2025-03-02T08:38:38.075091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        #初始化一个位置编码矩阵,大小是max_len*d_model\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        #初始化一个绝对位置编码矩阵,大小是max_len*1\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        \n",
    "        #定义一个变化矩阵，跳跃式的初始化\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        #奇数偶数分别赋值\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        #二维变三维\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        #将位置编码矩阵注册成模型的buffer，不跟随优化器同步更新\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad = False)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(1 - subsequent_mask)\n",
    "    \n",
    "x = embr\n",
    "dropout = 0.2\n",
    "max_len = 60\n",
    "pe = PositionalEncoding(d_model, dropout, max_len)\n",
    "pe_result = pe(x)\n",
    "print(pe_result)\n",
    "print(pe_result.shape)\n",
    "\n",
    "size = 5\n",
    "sm = subsequent_mask(size)\n",
    "print(sm)\n",
    "print(sm.shape)\n"
   ],
   "id": "8148833081c10ff8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0.0000,  -5.1462,   9.1621,  ...,  12.2159,   0.0000,  26.3734],\n",
      "         [-40.4962,   0.0000, -17.0170,  ...,   0.3184,  20.3970,   5.4490],\n",
      "         [-30.1651,  -0.0000, -23.5414,  ..., -10.9141,  32.8768, -14.9609],\n",
      "         [-19.3967,  -2.2812,   2.2749,  ...,  47.6101,  -4.9441,   0.0000]],\n",
      "\n",
      "        [[-52.7716,  11.5298,  29.8303,  ...,  -1.0770,   0.0000, -40.0424],\n",
      "         [-39.6873,  39.1438,   1.4642,  ...,  -9.5648,   0.0000,  -0.0000],\n",
      "         [ -0.0000,  12.0464, -16.8738,  ...,   0.0000,  20.3972,   5.4490],\n",
      "         [ -0.0000,  37.0059,  -8.9166,  ..., -15.6663,  51.8384,  -5.1618]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[1, 0, 0, 0, 0],\n",
      "         [1, 1, 0, 0, 0],\n",
      "         [1, 1, 1, 0, 0],\n",
      "         [1, 1, 1, 1, 0],\n",
      "         [1, 1, 1, 1, 1]]], dtype=torch.uint8)\n",
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:41:07.787539Z",
     "start_time": "2025-03-02T08:41:07.771701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def attention(query, key, value, mask = None, dropout=None):\n",
    "    #首先将query的最后一个维度提取，代表词嵌入的维度\n",
    "    d_k = query.size(-1)\n",
    "    print(d_k)\n",
    "    \n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    print(\"scores\", scores.shape)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0 , -1e9)\n",
    "        \n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "query = key = value = pe_result\n",
    "attn, p_attn = attention(query, key, value)\n",
    "\n",
    "print(attn)\n",
    "print(attn.shape)\n",
    "print(p_attn)\n",
    "print(p_attn.shape)"
   ],
   "id": "e1af12fde6fce2b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "scores torch.Size([2, 4, 4])\n",
      "tensor([[[  0.0000,  -5.1462,   9.1621,  ...,  12.2159,   0.0000,  26.3734],\n",
      "         [-40.4962,   0.0000, -17.0170,  ...,   0.3184,  20.3970,   5.4490],\n",
      "         [-30.1651,   0.0000, -23.5414,  ..., -10.9141,  32.8768, -14.9609],\n",
      "         [-19.3967,  -2.2812,   2.2749,  ...,  47.6101,  -4.9441,   0.0000]],\n",
      "\n",
      "        [[-52.7716,  11.5298,  29.8303,  ...,  -1.0770,   0.0000, -40.0424],\n",
      "         [-39.6873,  39.1438,   1.4642,  ...,  -9.5648,   0.0000,   0.0000],\n",
      "         [  0.0000,  12.0464, -16.8738,  ...,   0.0000,  20.3972,   5.4490],\n",
      "         [  0.0000,  37.0059,  -8.9166,  ..., -15.6663,  51.8384,  -5.1618]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T07:37:40.684528Z",
     "start_time": "2025-03-02T07:37:40.658341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)] )\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, head, embedding_dim, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert embedding_dim % head == 0\n",
    "        self.d_k = embedding_dim // head\n",
    "        self.head = head\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.linears = clones(nn.Linear(embedding_dim, embedding_dim), 4)\n",
    "        #初始化注意力张量\n",
    "        self.attn = None\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "    def forward(self,query, key, value, mask = None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            \n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        query, key, value = \\\n",
    "            [model(x).view(batch_size, -1, self.head, self.d_k).transpose(1,2)\n",
    "             for model , x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        x = x.transpose(1,2).contiguous().view(batch_size, -1, self.head * self.d_k)\n",
    "        \n",
    "        return self.linears[-1](x)\n",
    "    \n"
   ],
   "id": "39ad2145367de5de",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:42:55.023544Z",
     "start_time": "2025-03-02T08:42:54.998304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "head = 8\n",
    "embedding_dim = 512\n",
    "dropout = 0.2\n",
    "\n",
    "query = key = value = pe_result\n",
    "\n",
    "mask = Variable(torch.zeros(2,4,4))\n",
    "\n",
    "mha = MultiHeadedAttention(head, embedding_dim, dropout)\n",
    "\n",
    "\n",
    "print(\"query shape:\", query.shape)\n",
    "print(\"key shape:\", key.shape)\n",
    "print(\"value shape:\", value.shape)\n",
    "print(\"mask shape:\", mask.shape)\n",
    "mha_result = mha(query, key, value, mask)\n",
    "print(mha_result)\n",
    "print(mha_result.shape)\n"
   ],
   "id": "34cfd517eea51a70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: torch.Size([2, 4, 512])\n",
      "key shape: torch.Size([2, 4, 512])\n",
      "value shape: torch.Size([2, 4, 512])\n",
      "mask shape: torch.Size([2, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "tensor([[[ 5.5644,  1.5772, -2.9466,  ..., -4.7217,  5.2768,  7.6987],\n",
      "         [ 2.1447,  0.6680, -5.1555,  ...,  1.5196,  4.4446,  8.2820],\n",
      "         [-0.0343, -1.2638, -6.0603,  ...,  1.9803,  1.4331,  9.4950],\n",
      "         [ 2.1467, -4.9469, -3.4508,  ..., -0.5114,  3.7474, 10.1934]],\n",
      "\n",
      "        [[ 1.0332,  0.6051,  0.1534,  ..., -3.4456,  0.9186,  4.6134],\n",
      "         [ 0.1549, -0.2857, -0.8081,  ..., -7.1809,  3.1867,  5.4611],\n",
      "         [-0.9462, -2.5637, -1.4282,  ..., -2.1174,  0.5409,  6.4205],\n",
      "         [-0.4082,  1.2229, -1.4550,  ..., -0.4331,  0.4411,  8.0422]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:42:56.602391Z",
     "start_time": "2025-03-02T08:42:56.586382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w1 = nn.Linear(d_model,d_ff)\n",
    "        self.w2 = nn.Linear(d_ff,d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    def forward(self, x):\n",
    "        return self.w2(self.dropout(F.relu(self.w1(x))))\n",
    "    \n",
    "d_ff = 64\n",
    "d_model = 512\n",
    "dropout = 0.2\n",
    "\n",
    "x = mha_result\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "ff_result = ff(x)\n",
    "print(ff_result)\n",
    "print(ff_result.shape)"
   ],
   "id": "c1be8b04fda67ea5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0574,  0.5072, -2.4992,  ..., -0.3614,  1.7082, -0.5154],\n",
      "         [-0.1217,  1.2613, -1.7827,  ..., -1.4855,  0.1240,  1.0478],\n",
      "         [ 0.0790,  2.4579, -3.1313,  ..., -0.1956,  1.3494,  1.2364],\n",
      "         [ 0.9925,  1.3909, -2.2709,  ..., -0.5404,  0.6839,  1.1610]],\n",
      "\n",
      "        [[-1.3643,  2.4278, -2.5269,  ...,  0.0700, -0.9485, -1.7216],\n",
      "         [ 0.8627,  0.9195, -1.8312,  ...,  0.5692,  0.0035,  0.0191],\n",
      "         [ 0.1311,  1.8305, -0.9359,  ...,  1.3486,  0.2745, -1.1639],\n",
      "         [-1.7927,  2.4690, -0.4020,  ...,  1.5674, -0.3094, -2.2710]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "前馈全连接层：再transform中前馈全连接层就是具有两层线性层的全连接网络\n",
    "\n",
    "考虑注意力机制可能对复杂过程拟合程度不够，通过增加两层网络来增强模型的能力\n",
    "\n",
    "relu激活函数"
   ],
   "id": "35c2466933b9b211"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:42:59.134744Z",
     "start_time": "2025-03-02T08:42:59.118744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout = 0.1):\n",
    "        #d_model:代表词嵌入的维度，同时也是线性层的输入维度和输出维度\n",
    "        #d_ff： 代表第一个线性层的输出维度，和第二个线性层的输入维度\n",
    "        \n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        \n",
    "        self.w1 = nn.Linear(d_model, d_ff)\n",
    "        self.w2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.w2(self.dropout(F.relu(self.w1(x))))\n",
    "    \n",
    "\n",
    "d_model = 512\n",
    "d_ff = 64\n",
    "dropout=0.2\n",
    "\n",
    "x = mha_result\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "ff_result = ff(x)\n",
    "\n",
    "\n",
    "print(ff_result)\n",
    "print(ff_result.shape)"
   ],
   "id": "235773e049d61885",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.5999e-02, -1.8583e+00,  6.2025e-03,  ..., -1.4832e+00,\n",
      "           3.1085e-01,  2.5882e-01],\n",
      "         [-1.8909e+00, -1.3611e+00,  1.1367e+00,  ..., -7.8875e-01,\n",
      "           3.7964e-01,  2.7609e-01],\n",
      "         [-2.0618e+00, -2.7013e+00,  1.0881e+00,  ..., -9.9657e-01,\n",
      "           1.5406e+00, -2.7545e+00],\n",
      "         [-2.6390e+00, -2.1137e+00,  1.7532e+00,  ..., -5.3152e-01,\n",
      "           2.1448e+00, -3.7907e-01]],\n",
      "\n",
      "        [[-2.3052e+00,  3.2439e-01, -2.0018e+00,  ..., -1.1056e+00,\n",
      "           7.3149e-01,  3.5918e-01],\n",
      "         [-2.4998e+00, -3.9661e-01, -4.2757e-01,  ..., -3.5952e-01,\n",
      "           4.1522e-01, -4.5117e-01],\n",
      "         [-1.4586e+00, -8.8199e-01,  5.2307e-02,  ..., -3.3271e-01,\n",
      "          -6.1155e-01,  1.0115e-01],\n",
      "         [-2.2082e+00, -9.2416e-02, -3.9354e-01,  ..., -2.2430e+00,\n",
      "          -2.0458e-03, -1.4116e+00]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "规范化层：通过多层计算后参数可能出现过大或过小，导致学习出现异常，模型收敛变慢，让特征值在合理范围内\n",
   "id": "6422506b911d318f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:43:00.961046Z",
     "start_time": "2025-03-02T08:43:00.945785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps = 1e-6):\n",
    "        #featrues代表词嵌入的维度\n",
    "        super(LayerNorm, self).__init__()\n",
    "        #nn.Parameter进行封装，代表他们也是模型中的参数\n",
    "        self.a2 = nn.Parameter(torch.ones(features))\n",
    "        self.b2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #对x进行最后一个维度上求均值，维度保持一致\n",
    "        #对x进行最后一个维度上求标准差，维度保持一致\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        # *是点乘\n",
    "        return self.a2 * (x - mean)/(std + self.eps) + self.b2\n",
    "    \n",
    "    \n",
    "featrues = d_model = 512\n",
    "eps = 1e-6\n",
    "x = ff_result\n",
    "ln = LayerNorm(featrues, eps)\n",
    "ln_result = ln(x)\n",
    "\n",
    "print(ln_result)\n",
    "print(ln_result.shape)"
   ],
   "id": "9ae01d594c04e664",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1034, -1.4535,  0.0395,  ..., -1.1531,  0.2835,  0.2418],\n",
      "         [-1.2842, -0.9211,  0.7911,  ..., -0.5287,  0.2721,  0.2012],\n",
      "         [-1.2299, -1.6172,  0.6782,  ..., -0.5846,  0.9523, -1.6495],\n",
      "         [-1.5835, -1.2694,  1.0433,  ..., -0.3231,  1.2775, -0.2319]],\n",
      "\n",
      "        [[-1.4821,  0.1790, -1.2904,  ..., -0.7243,  0.4362,  0.2010],\n",
      "         [-2.0144, -0.2976, -0.3229,  ..., -0.2674,  0.3650, -0.3422],\n",
      "         [-1.4055, -0.8767, -0.0200,  ..., -0.3731, -0.6288,  0.0248],\n",
      "         [-1.4973, -0.0760, -0.2783,  ..., -1.5207, -0.0152, -0.9622]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "子层连接结构\n",
    "\n",
    "残差连接（跳跃连接）"
   ],
   "id": "e16ccf0329b2d897"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:45:10.726222Z",
     "start_time": "2025-03-02T08:45:10.710525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout=0.1):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        #实例化规范化层的对象\n",
    "        self.size = size\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    \n",
    "    def forward(self,x, sublayer):\n",
    "        #sublayer：该子层连接中子层函数\n",
    "        #首先将x进行规范化，然后送入子层函数中处理，处理结果进入dropout层，最后进行残差链接  \n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "\n",
    "size = d_model = 512\n",
    "head = 8\n",
    "dropout = 0.2\n",
    "\n",
    "x = pe_result\n",
    "mask = Variable(torch.zeros(2,4,4))\n",
    "self_attn = MultiHeadedAttention(head, d_model)\n",
    "\n",
    "sublayer = lambda x : self_attn(x, x, x, mask)\n",
    "sc = SublayerConnection(size, dropout)\n",
    "sc_result = sc(x, sublayer)\n",
    "\n",
    "print(sc_result)\n",
    "print(sc_result.shape)"
   ],
   "id": "a4f4296c02284637",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "tensor([[[ 1.4768e-01, -5.1178e+00,  8.7390e+00,  ...,  1.2379e+01,\n",
      "           0.0000e+00,  2.6193e+01],\n",
      "         [-4.0109e+01,  1.7407e-01, -1.7307e+01,  ...,  5.2211e-01,\n",
      "           2.0397e+01,  5.4667e+00],\n",
      "         [-2.9882e+01,  1.2204e-01, -2.3698e+01,  ..., -1.0835e+01,\n",
      "           3.3145e+01, -1.4990e+01],\n",
      "         [-1.9086e+01, -2.3130e+00,  1.9263e+00,  ...,  4.7760e+01,\n",
      "          -4.6085e+00, -8.1126e-02]],\n",
      "\n",
      "        [[-5.2772e+01,  1.2074e+01,  2.9862e+01,  ..., -9.5817e-01,\n",
      "           3.9325e-03, -3.9711e+01],\n",
      "         [-3.9526e+01,  3.9144e+01,  1.4076e+00,  ..., -9.2055e+00,\n",
      "           1.1838e-01,  3.5946e-01],\n",
      "         [ 4.4848e-01,  1.2614e+01, -1.6872e+01,  ...,  1.7651e-01,\n",
      "           2.0259e+01,  5.7723e+00],\n",
      "         [ 4.0136e-01,  3.7363e+01, -8.9716e+00,  ..., -1.5375e+01,\n",
      "           5.1927e+01, -4.8413e+00]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "编码器层作用：对输入的特征提取",
   "id": "4e011bbf4ceb64f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:45:41.131513Z",
     "start_time": "2025-03-02T08:45:41.099985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        #size:代表词嵌入维度\n",
    "        #self_attn：多头自注意力子层的实例化对象\n",
    "        #feed_forward：前馈全连接层实例化对象\n",
    "        #dropout：质零比例\n",
    "        super(EncoderLayer,self).__init__() \n",
    "        \n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.size = size\n",
    "        \n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "    def forward(self, x, mask):\n",
    "        # x：代表上一层的传入张量\n",
    "        # mask：代表掩码张量\n",
    "        #首先让x经过第一个子层连接结构，内部包含多头自注意力机制子层\n",
    "        #再让x经过第二个子层连接结构，内部包含前馈全连接网络\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "    \n",
    "    \n",
    "size = d_model = 512\n",
    "head = 8\n",
    "d_ff = 64\n",
    "x = pe_result\n",
    "dropout = 0.2\n",
    "\n",
    "self_attn = MultiHeadedAttention(head, d_model)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "mask = Variable(torch.zeros(2,4,4))\n",
    "\n",
    "el = EncoderLayer(size, self_attn, ff, dropout)\n",
    "el_result = el(x,mask)\n",
    "print(el_result)\n",
    "print(el_result.shape)"
   ],
   "id": "d9260f8037d18758",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "tensor([[[  0.1339,  -4.8128,   9.4395,  ...,  12.0258,   0.3797,  26.4566],\n",
      "         [-39.9285,   0.1643, -16.6818,  ...,   0.2159,  20.0679,   5.3704],\n",
      "         [-30.0505,   0.1002, -23.3042,  ..., -10.6114,  32.6926, -14.9643],\n",
      "         [-19.0091,  -2.2298,   2.0419,  ...,  47.8538,  -4.8858,  -0.1000]],\n",
      "\n",
      "        [[-52.5995,  12.1280,  30.3564,  ...,  -1.2975,   0.3369, -40.3583],\n",
      "         [-39.6446,  39.4865,   1.5508,  ...,  -9.5648,   0.2210,   0.0864],\n",
      "         [ -0.1130,  12.0464, -16.6524,  ...,  -0.5318,  20.1564,   5.0981],\n",
      "         [  0.3294,  36.7571,  -8.8828,  ..., -15.9101,  51.9819,  -5.4290]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "编码器：由N个编码器层堆叠而成",
   "id": "afbebf90f562694f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:45:42.206785Z",
     "start_time": "2025-03-02T08:45:42.155628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        #layer:代表编码器层\n",
    "        #N：代表编码器中有几个layer\n",
    "        \n",
    "        #首先使用clones函数克隆N个编码器层放置在self.layers中\n",
    "        self.layers = clones(layer, N)\n",
    "        #规范化层\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    def forward(self, x, mask):\n",
    "        \n",
    "        #让x依次经历N个编码器层的处理，最后再经过规范化层就可以输出了\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "size = d_model = 512\n",
    "head = 8\n",
    "d_ff = 64\n",
    "c = copy.deepcopy\n",
    "x = pe_result\n",
    "dropout = 0.2\n",
    "\n",
    "attn = MultiHeadedAttention(head, d_model)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "layer = EncoderLayer(size, c(attn), c(ff), dropout)\n",
    "\n",
    "N = 8\n",
    "\n",
    "mask = Variable(torch.zeros(2,4,4))\n",
    "\n",
    "en = Encoder(layer, N)\n",
    "en_result = en(x,mask)\n",
    "print(en_result)\n",
    "print(en_result.shape)"
   ],
   "id": "8f5c79a43eb6fede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "tensor([[[ 0.0485, -0.3770,  0.3840,  ...,  0.4731,  0.1529,  0.8842],\n",
      "         [-1.5488,  0.0735, -0.5730,  ...,  0.0372,  0.8259,  0.2583],\n",
      "         [-1.1485, -0.1273, -1.0775,  ..., -0.4996,  1.3942, -0.7420],\n",
      "         [-0.7062, -0.2043,  0.2021,  ...,  1.7537, -0.1897, -0.0718]],\n",
      "\n",
      "        [[-1.9288,  0.4005,  1.3065,  ..., -0.1753,  0.0040, -1.5410],\n",
      "         [-1.5767,  1.4986,  0.0275,  ..., -0.5608,  0.0090,  0.0639],\n",
      "         [ 0.0993,  0.5305, -0.5738,  ..., -0.0777,  0.7131,  0.2292],\n",
      "         [ 0.1862,  1.4317, -0.2575,  ..., -0.5594,  2.0354, -0.1278]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "解码器：每个解码器层根据给定的输入向目标方向进行特征提取",
   "id": "53920d0e29733905"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:45:54.811632Z",
     "start_time": "2025-03-02T08:45:54.784995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        #size：词嵌入维度\n",
    "        #self_attn：多头自注意力机制实例化\n",
    "        #src_attn：常规注意力机制实例化对象\n",
    "        #feed_forward：前馈全连接层\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        #将参数传入类中\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        #根据解码器层的结构，需要clones函数克隆3个子层连接对象\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "    def forward(self, x, memory, source_mask, target_mask):\n",
    "        #x：上一层输出\n",
    "        #memory：编码器的语义存储张量\n",
    "        #source_mask：源数据的掩码张量\n",
    "        #target_mask：目标数据的掩码张量\n",
    "        m = memory\n",
    "        #第一步让x经历第一个子层，多头自注意力机制的子层\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, target_mask))\n",
    "        \n",
    "        #第二步让x经历第二个子层，常规的注意力机制的子层，Q!=K=V\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, target_mask))\n",
    "        \n",
    "        #第三步让x经历第三个子层，前馈全连接层\n",
    "        x = self.sublayer[2](x, self.feed_forward)\n",
    "        return x\n",
    "        \n",
    "size = d_model = 512\n",
    "head = 8\n",
    "d_ff = 64\n",
    "c = copy.deepcopy\n",
    "x = pe_result\n",
    "dropout = 0.2\n",
    "memory = en_result\n",
    "\n",
    "\n",
    "\n",
    "self_attn = src_attn = MultiHeadedAttention(head, d_model)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "layer = EncoderLayer(size, c(attn), c(ff), dropout)\n",
    "\n",
    "N = 8\n",
    "\n",
    "mask = Variable(torch.zeros(2,4,4))\n",
    "source_mask = target_mask = mask\n",
    "\n",
    "dl = DecoderLayer(size, self_attn, src_attn, ff, dropout)\n",
    "dl_result = dl(x, memory, source_mask, target_mask)\n",
    "print(dl_result)\n",
    "print(dl_result.shape)"
   ],
   "id": "192732a631c99183",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "tensor([[[-4.5474e-01, -4.9912e+00,  9.1455e+00,  ...,  1.2497e+01,\n",
      "          -2.2109e-02,  2.5969e+01],\n",
      "         [-4.0691e+01, -1.0692e-01, -1.7052e+01,  ...,  4.6210e-01,\n",
      "           2.0132e+01,  5.5156e+00],\n",
      "         [-3.0662e+01, -1.1548e-02, -2.3714e+01,  ..., -1.0663e+01,\n",
      "           3.3049e+01, -1.5583e+01],\n",
      "         [-1.9982e+01, -2.0805e+00,  1.9832e+00,  ...,  4.7732e+01,\n",
      "          -4.9690e+00, -1.3161e-01]],\n",
      "\n",
      "        [[-5.2741e+01,  1.1251e+01,  2.9056e+01,  ..., -2.4342e-01,\n",
      "           3.5467e-01, -4.0090e+01],\n",
      "         [-3.9707e+01,  3.9034e+01,  1.0170e+00,  ..., -8.7006e+00,\n",
      "          -4.6611e-01,  6.5476e-02],\n",
      "         [-3.0150e-01,  1.2530e+01, -1.7372e+01,  ...,  8.1796e-01,\n",
      "           2.0792e+01,  6.1759e+00],\n",
      "         [ 2.4632e-02,  3.6860e+01, -9.1811e+00,  ..., -1.5065e+01,\n",
      "           5.1701e+01, -5.0168e+00]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "编码器：根据编码器的结果以及上一次预测的结果，对下一次可能出现的值进行特征表示",
   "id": "e2bd710743ca0423"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:46:58.857026Z",
     "start_time": "2025-03-02T08:46:58.762065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self, x, memory, source_mask, target_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, source_mask, target_mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "size = d_model = 512\n",
    "head = 8\n",
    "d_ff = 64\n",
    "c = copy.deepcopy\n",
    "x = pe_result\n",
    "dropout = 0.2\n",
    "memory = en_result\n",
    "\n",
    "\n",
    "\n",
    "attn = MultiHeadedAttention(head, d_model)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "layer = DecoderLayer(size, c(attn), c(attn), c(ff), dropout)\n",
    "\n",
    "N = 8\n",
    "\n",
    "mask = Variable(torch.zeros(2,4,4))\n",
    "source_mask = target_mask = mask\n",
    "\n",
    "de = Decoder(layer, N)\n",
    "de_result = de(x, memory, source_mask, target_mask)\n",
    "print(de_result)\n",
    "print(de_result.shape)"
   ],
   "id": "f0599746c5c6059",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "tensor([[[-0.0124, -0.2119,  0.3868,  ...,  0.5012,  0.0651,  0.8903],\n",
      "         [-1.7254,  0.1375, -0.6774,  ...,  0.1407,  0.9314,  0.0275],\n",
      "         [-1.2846, -0.0292, -1.0038,  ..., -0.2769,  1.3334, -0.9056],\n",
      "         [-0.7423, -0.2329,  0.0095,  ...,  1.9385, -0.2565, -0.1007]],\n",
      "\n",
      "        [[-1.8028,  0.4237,  1.1409,  ..., -0.0633,  0.2591, -1.5145],\n",
      "         [-1.3532,  1.2917,  0.0211,  ..., -0.3772,  0.1087,  0.0908],\n",
      "         [ 0.2307,  0.5111, -0.6733,  ...,  0.0645,  1.0015,  0.2213],\n",
      "         [ 0.2978,  1.5189, -0.2326,  ..., -0.4643,  2.1169, -0.1431]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "线性层和softmax\n",
    "\n",
    "线性层：通过对上一步的线性变化，得到指定的维度输出"
   ],
   "id": "560316e594218eb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:47:03.491295Z",
     "start_time": "2025-03-02T08:47:03.446777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#functional 装载了网络层中那些只进行计算，而没有参数的层\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.project = nn.Linear(d_model, vocab_size)\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.project(x), dim = -1)\n",
    "    \n",
    "d_model = 512\n",
    "vocab_size = 1000\n",
    "x = pe_result\n",
    "\n",
    "gen = Generator(d_model, vocab_size)\n",
    "gen_result = de(x, memory, source_mask, target_mask)\n",
    "print(gen_result)\n",
    "print(gen_result.shape)"
   ],
   "id": "35ce83ba80734d7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "tensor([[[ 0.0039, -0.2045,  0.3771,  ...,  0.4905,  0.0487,  0.8767],\n",
      "         [-1.6801,  0.1297, -0.6928,  ...,  0.1438,  0.9744,  0.0816],\n",
      "         [-1.2891, -0.0220, -1.0026,  ..., -0.3274,  1.3494, -0.8548],\n",
      "         [-0.7581, -0.1939,  0.0179,  ...,  1.9780, -0.2731, -0.1232]],\n",
      "\n",
      "        [[-1.8163,  0.3787,  1.1436,  ..., -0.0278,  0.2496, -1.5390],\n",
      "         [-1.3462,  1.3552,  0.0358,  ..., -0.3515,  0.1283,  0.0743],\n",
      "         [ 0.1570,  0.5776, -0.7021,  ...,  0.0359,  1.0601,  0.2391],\n",
      "         [ 0.2285,  1.5008, -0.2471,  ..., -0.4749,  2.1236, -0.1092]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:03:34.594250Z",
     "start_time": "2025-03-02T09:03:34.519473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, source_embed, target_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = source_embed\n",
    "        self.tgt_embed = target_embed\n",
    "        self.generator = generator\n",
    "    def forward(self, source, target, source_mask, target_mask):\n",
    "        return self.decode(self.encode(source, source_mask), source_mask, target, target_mask)\n",
    "    \n",
    "    def encode(self, source, source_mask):\n",
    "        return self.encoder(self.src_embed(source), source_mask)\n",
    "    \n",
    "    def decode(self, memory, source_mask, target, target_mask):\n",
    "        return self.decoder(self.tgt_embed(target), memory, source_mask, target_mask)\n",
    "    \n",
    "vocab_size = 1000\n",
    "d_model = 512\n",
    "encoder = en\n",
    "decoder = de\n",
    "source_embed = nn.Embedding(vocab_size, d_model)\n",
    "target_embed = nn.Embedding(vocab_size, d_model)\n",
    "generator = gen\n",
    "\n",
    "source = target = Variable(torch.LongTensor([[10,3,124,244],[33,222,5,11]]))\n",
    "\n",
    "source_mask = target_mask = Variable(torch.zeros(2,4,4))\n",
    "\n",
    "ed = EncoderDecoder(encoder, decoder, source_embed, target_embed, generator)\n",
    "ed_result = ed(source, target, source_mask, target_mask)\n",
    "print(ed_result)\n",
    "print(ed_result.shape)"
   ],
   "id": "3910ed94a41bd8c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "64\n",
      "scores torch.Size([2, 8, 4, 4])\n",
      "tensor([[[-1.7757e-01,  4.4075e-01, -4.3779e-02,  ...,  9.9333e-01,\n",
      "          -6.8268e-01, -4.7330e-01],\n",
      "         [-1.7906e-01, -6.4976e-01,  8.7825e-01,  ...,  5.8519e-01,\n",
      "          -5.5499e-01, -3.6843e-01],\n",
      "         [-7.0453e-01,  7.5184e-01,  3.1185e-01,  ...,  2.7984e-03,\n",
      "          -3.4945e-01, -9.2838e-01],\n",
      "         [-1.2929e+00,  2.0220e-01, -1.1081e-03,  ..., -1.4032e-02,\n",
      "          -1.1699e+00,  2.8785e-01]],\n",
      "\n",
      "        [[ 1.6742e+00,  1.0764e+00,  2.0500e-01,  ...,  4.4268e-01,\n",
      "           1.5746e+00, -1.8201e+00],\n",
      "         [ 1.2391e+00,  2.0548e+00,  4.4097e-03,  ...,  6.2205e-02,\n",
      "           1.4235e+00, -1.8201e+00],\n",
      "         [ 2.9513e-01,  1.3044e+00,  8.4395e-01,  ...,  4.9126e-01,\n",
      "           2.0984e+00, -2.2961e+00],\n",
      "         [ 1.5878e+00,  1.5733e+00, -2.5217e-01,  ...,  1.2901e-01,\n",
      "           2.0284e+00, -2.1132e+00]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "make_model函数",
   "id": "9295bc2571d90609"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:06:24.807576Z",
     "start_time": "2025-03-02T09:06:24.493329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_model(source_vocab, target_vocab, N=6, d_model=512, d_ff=2048, head=8, droupout=0.2):\n",
    "    #source_vocab:代表源数据的词汇总数\n",
    "    #target_vocab：代表目标数据的词汇总数\n",
    "    #N：代表编码器和解码器堆叠的层数\n",
    "    #d_model：词嵌入的维度\n",
    "    #d_ff：前馈全连接层中变换矩阵的维度\n",
    "    #head：头数\n",
    "    c = copy.deepcopy\n",
    "    \n",
    "    attn = MultiHeadedAttention(head, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    \n",
    "    #实例化模型model，利用EncoderDecoder类\n",
    "    #编码器结构两个子层，attention和前馈全连接\n",
    "    #解码器结构三个子层，两个attention和前馈全连接\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embedding(d_model, source_vocab), c(position)),\n",
    "        nn.Sequential(Embedding(d_model, target_vocab), c(position)),\n",
    "        Generator(d_model, target_vocab)\n",
    "    )\n",
    "    \n",
    "    #初始化模型参数，维度大于1，将矩阵初始化成一个服从均匀分布的矩阵\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "        \n",
    "    return model\n",
    "    \n",
    "source_vocab = 11\n",
    "target_vacab = 11\n",
    "N=6\n",
    "\n",
    "if __name__=='__main__':\n",
    "    res = make_model(source_vocab, target_vacab, N)\n",
    "    print(res)"
   ],
   "id": "5f6f3eed032bc2a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderDecoder(\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm()\n",
      "  )\n",
      "  (src_embed): Sequential(\n",
      "    (0): Embedding(\n",
      "      (lut): Embedding(11, 512)\n",
      "    )\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (tgt_embed): Sequential(\n",
      "    (0): Embedding(\n",
      "      (lut): Embedding(11, 512)\n",
      "    )\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (generator): Generator(\n",
      "    (project): Linear(in_features=512, out_features=11, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "COPY任务：帮助我们断定模型多有过程是否正常，是否具有基本学习能力\n",
    "\n",
    "第一步：构建数据集生成器\n",
    "第二步：模型及其优化器\n",
    "第三步：训练评估\n",
    "第四步：使用模型进行贪婪解码"
   ],
   "id": "b84da4dcfe011ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:32:22.051204Z",
     "start_time": "2025-03-02T09:32:22.029869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#from pyitcast.transformer_utils import Batch\n",
    "\n",
    "def data_generator(V, batch, num_batch):\n",
    "    for i in range(num_batch):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
    "        data[:, 0] = 1\n",
    "        \n",
    "        source= Variable(data, requires_grad = False)\n",
    "        target= Variable(data, requires_grad = False)\n",
    "        \n",
    "        yield Batch(source, target)"
   ],
   "id": "22bac7419433d457",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2147841568.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[90], line 3\u001B[1;36m\u001B[0m\n\u001B[1;33m    def data_generator(V, batch, num_batch):\u001B[0m\n\u001B[1;37m                                            ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "模型\n",
    "第一步：导包\n",
    "第二步：导入数据集\n",
    "第三步：构建模型输入的批次数据\n",
    "第四步：构建训练和评估函数\n",
    "第五步：训练评估\n",
    "\n"
   ],
   "id": "6cbb79eee82f978e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a4a1f38051c5178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from pyitcast.transformer import TransformerModel\n"
   ],
   "id": "1995d1dab02fe1a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
